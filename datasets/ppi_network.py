# -*- coding: utf-8 -*-
"""PPI_network.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KzMDWlLUU8p3VUXj0Y2AGXPtnLS2X5Mi
"""

### The required libraries and packages ###
import networkx as nx
import networkx.utils as nu
import requests
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from matplotlib import cm
from networkx.algorithms.assortativity import average_degree_connectivity
import pickle
import os
import json

def print_graph_info(graph):
  print("name:", graph.name)
  print("Directed graph:", graph.is_directed())
  print("Number of nodes:", graph.number_of_nodes())
  print("Number of edges:", graph.number_of_edges())
  # calculate the average degree
  avg_deg = sum(dict(average_degree_connectivity(graph)).values()) / len(graph)
  # print the average degree
  print("average degree:", avg_deg)

def plot_graph(G):
  pos = nx.spring_layout(G)
  plt.figure(figsize = (11,11),facecolor = [0.7,0.7,0.7,0.4])
  nx.draw_networkx(G)
  plt.axis('off')
  plt.show

def PPI_network_creation_STRING(column_gene, patient_df, threshold):
    # Convert the input row to a list and remove duplicates while preserving order
    elements = column_gene.tolist()
    unique_elements = list(set(elements))
    unique_elements.sort(key=elements.index)

    # Get list of protein names from the patient dataframe columns
    # Replace spaces with '+' to match the format of the STRING API
    unique_elements = [element.replace(" ", "+") for element in unique_elements]
    # Join the protein names using '%0d' as a delimiter
    proteins = '%0d'.join(unique_elements)
    # Construct the URL for the STRING API using the protein names and species code
    url = 'https://string-db.org/api/tsv/network?identifiers=' + proteins + '&species=9606'

    # Send a GET request to the API and parse the response into a dataframe
    r = requests.get(url)
    lines = r.text.split('\n')
    data = [l.split('\t') for l in lines[:-1]] # drop the empty final row
    df = pd.DataFrame(data[1:], columns=data[0])
    interactions = df[['preferredName_A', 'preferredName_B', 'score']]

    # Create a graph from the protein interactions using NetworkX
    G = nx.Graph(name='Protein Interaction Graph ' + str(patient_df.columns[0]))
    interactions = np.array(interactions)
    for interaction in interactions:
        a = interaction[0] # protein a node
        b = interaction[1] # protein b node
        if float(interaction[2]) >= threshold: # the scores represent the confidence of the interaction so we are distinguishing by the thresholds
          w = 1 # assigning 1 if the score is above the given threshold so the interaction is considered
          G.add_edges_from([(a, b)]) # add weighted edge to graph

    # Add node features to the graph from the patient dataframe
    for i in G.nodes:
        G.nodes[i]['features'] = []

    snps_list = column_gene.index.tolist()
    node_list = G.nodes
    for i in range(len(elements)):
        if elements[i] in G.nodes:
            feature_value = patient_df.loc[snps_list[i]].values[0]
            G.nodes[elements[i]]['features'].append(float(feature_value))

    # Pad the feature vectors of nodes with fewer features than the maximum
    max_features = max([len(G.nodes[node]['features']) for node in G.nodes])
    for node in G.nodes:
        features = G.nodes[node]['features']
        num_features = len(features)
        if num_features < max_features:
            features += [0.0] * (max_features - num_features)
        G.nodes[node]['features'] = features

    # Convert the graph to an adjacency matrix and return as a dictionary
    A = nx.adjacency_matrix(G).todense()
    D = {'sample':patient_df.columns[0],
              'Graph': G,
              'Adjacency_matrix':A}
    return D
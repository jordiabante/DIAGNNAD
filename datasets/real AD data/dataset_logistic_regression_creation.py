# -*- coding: utf-8 -*-
"""Dataset_logistic_regression_creation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19JCKNJfyMsKUAffZU2uDESuYRl_6P53O
"""

from google.colab import drive
drive.mount('/content/drive')

import pickle
import pandas as pd
import numpy as np
import random
import os
os.chdir('/content/drive/MyDrive/Colab Notebooks/GitHub')
from labelling import label_ADNI
import gc
from sklearn.model_selection import KFold

# Percorso del file GZIP
file_path = '/content/drive/MyDrive/PROJECT/dataset_full_real_phenotype.csv.gz'

df = pd.read_csv(file_path, sep='\t', dtype=str)
df.set_index('Unnamed: 0', inplace=True)
df = df.astype(float)
df

class_0 = pd.DataFrame(columns=df.columns)
class_1 = pd.DataFrame(columns=df.columns)

class_1 = df[df['y'] == 1]
class_0 = df[df['y'] == 0]

training_set = []
validation_set = []


print(len(class_1))
print(len(class_0))
for i in range(10):
    train_size_0 = 260 # calcola la dimensione del set di train

    train_0 = class_0.sample(n=train_size_0, replace=False) # seleziona casualmente gli elementi del set di train
    val_0 = class_0.loc[~class_0.index.isin(train_0.index)] # crea il set di validation con gli elementi rimanenti

    train_1 = class_1.sample(n=train_size_0, replace=False)
    val_1 = class_1.loc[~class_1.index.isin(train_1.index)] # crea il set di validation con gli elementi rimanenti

    training_set.append(pd.concat([train_1, train_0]))
    validation_set.append(pd.concat([val_1, val_0]))
    print(len(training_set))
    print(len(validation_set))

with open('/content/drive/MyDrive/PROJECT/training_set_Age_Sex.pickle', 'wb') as handle:
    pickle.dump(training_set, handle, protocol=pickle.HIGHEST_PROTOCOL)

with open('/content/drive/MyDrive/PROJECT/validation_set_Age_Sex.pickle', 'wb') as handle:
    pickle.dump(validation_set, handle, protocol=pickle.HIGHEST_PROTOCOL)

# checkejem que s'obri correctament:
with open('/content/drive/MyDrive/PROJECT/training_set_Age_Sex.pickle', 'rb') as handle:
    dataset = pickle.load(handle)
len(dataset)

dataset[0]


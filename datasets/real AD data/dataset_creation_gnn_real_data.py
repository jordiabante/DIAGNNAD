# -*- coding: utf-8 -*-
"""dataset_creation_GNN_real_data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qDm-tUrJapNTirk2XpzQ0nHBD6XlEgYw
"""

import networkx as nx
import networkx.utils as nu
import requests
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from matplotlib import cm
from networkx.algorithms.assortativity import average_degree_connectivity
import pickle
import torch
!pip install torch_geometric
import torch_geometric.data as pyg_data
import torch_geometric.utils
import ast
import torch
import torch.nn.functional as F
import random
from torch.nn import Linear
import json

from torch_geometric.datasets import TUDataset
from torch_geometric.loader import DataLoader
from torch_geometric.nn import DenseGraphConv, DMoNPooling, GCNConv
from torch_geometric.utils import to_dense_adj, to_dense_batch


from google.colab import drive
drive.mount('/content/drive')
import os
os.chdir('/content/drive/MyDrive/Colab Notebooks/GitHub')
from ppi_network import print_graph_info, plot_graph

with open('/content/drive/MyDrive/PROJECT/NCBI_graph_PET.pickle', 'rb') as handle:
    lista_dizionari = pickle.load(handle)

print_graph_info(lista_dizionari[2][0]['Graph'])

plot_graph(lista_dizionari[2][0]['Graph'])

with open('/content/drive/MyDrive/PROJECT/training_set_Age_Sex.pickle', 'rb') as handle: #dataset_folds_Age_Sex
    training_set = pickle.load(handle)

with open('/content/drive/MyDrive/PROJECT/validation_set_Age_Sex.pickle', 'rb') as handle: #dataset_folds_Age_Sex
    validation_set = pickle.load(handle)

training_set_dict = []
for k in lista_dizionari:
  training_set_dict_flag = []
  for i in training_set:
      training_flag = []
      for j in k:
        if j['sample'] in i.index.tolist():
          training_flag.append(j)
      training_set_dict_flag.append(training_flag)
  training_set_dict.append(training_set_dict_flag)


validation_set_dict = []
for k in lista_dizionari:
  validation_set_dict_flag = []
  for i in validation_set:
      validation_flag = []
      for j in k:
        if j['sample'] in i.index.tolist():
          validation_flag.append(j)
      validation_set_dict_flag.append(validation_flag)
  validation_set_dict.append(validation_set_dict_flag)

training_list = []
node_dict_list = []

for j in training_set_dict:
  training_list_flag = []
  for k in j:
      training_data_flag = []
      for i in k:
        node_names = list(i['Graph'].nodes)
        node_dict = {node_names[i]: i for i in range(len(node_names))}
        node_features = [i['Graph'].nodes[n]['features'] for n in node_names]
        x = torch.tensor(node_features, dtype=torch.float)
        edge_index = []
        for e in i['Graph'].edges:
            u, v = e[0], e[1]
            u_idx, v_idx = node_dict[u], node_dict[v]
            edge_index.append([u_idx, v_idx])
            edge_index.append([v_idx, u_idx])
        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()
        y = torch.tensor(i['y'], dtype = torch.float)
        AGE = torch.tensor(i['AGE'], dtype = torch.float)
        PTGENDER = torch.tensor(i['PTGENDER'], dtype = torch.float)
        data = pyg_data.Data(x=x, edge_index=edge_index, y=y, AGE = AGE, PTGENDER = PTGENDER)
        training_data_flag.append(data)
      training_list_flag.append(training_data_flag)
  training_list.append(training_list_flag)
  node_dict_list.append(node_dict)


validation_list = []

for j in validation_set_dict:
  validation_list_flag = []
  for k in j:
      validation_data_flag = []
      for i in k:
        node_names = list(i['Graph'].nodes)
        node_dict = {node_names[i]: i for i in range(len(node_names))}
        node_features = [i['Graph'].nodes[n]['features'] for n in node_names]
        x = torch.tensor(node_features, dtype=torch.float)
        edge_index = []
        for e in i['Graph'].edges:
            u, v = e[0], e[1]
            u_idx, v_idx = node_dict[u], node_dict[v]
            edge_index.append([u_idx, v_idx])
            edge_index.append([v_idx, u_idx])
        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()
        y = torch.tensor(i['y'] ,dtype=torch.float)
        AGE = torch.tensor(i['AGE'], dtype = torch.float)
        PTGENDER = torch.tensor(i['PTGENDER'], dtype = torch.float)
        data = pyg_data.Data(x=x, edge_index=edge_index, y=y, AGE = AGE, PTGENDER = PTGENDER)
        validation_data_flag.append(data)
      validation_list_flag.append(validation_data_flag)
  validation_list.append(validation_list_flag)

print(training_list[0][9][9].num_nodes)
print(validation_list[0][0][0].num_edges)
len(training_list[0])

graph = nx.Graph()
graph.add_nodes_from(range(training_list[2][9][9].num_nodes))
graph.add_edges_from(training_list[2][9][9].edge_index.t().tolist())
plot_graph(graph)

print_graph_info(graph)

thresholds = [0, 0.5, 0.75]
for i in range(len(training_list)):
    with open('/content/drive/MyDrive/PROJECT/training_' + str(thresholds[i]) +'_GNN_PET.pickle', 'wb') as handle:
        pickle.dump(training_list[i], handle, protocol=pickle.HIGHEST_PROTOCOL)

    with open('/content/drive/MyDrive/PROJECT/validation_' + str(thresholds[i]) + '_GNN_PET.pickle', 'wb') as handle:
        pickle.dump(validation_list[i], handle, protocol=pickle.HIGHEST_PROTOCOL)

    file_1 = open('/content/drive/MyDrive/PROJECT/node_dict' + str(thresholds[i]) + '.json','w')
    json.dump(node_dict_list[i],file_1)
    file_1.close()

with open('/content/drive/MyDrive/PROJECT/validation_0.5_GNN_PET.pickle', 'rb') as handle:
    dataset = pickle.load(handle)

dataset[0][0].num_edges
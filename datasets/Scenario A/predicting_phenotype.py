# -*- coding: utf-8 -*-
"""predicting phenotype.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QzJD9qIGJ_gplFiCk-hL98Da1vxrpvZe
"""

from google.colab import drive
drive.mount('/content/drive')

##import library
import gc
import os
os.chdir('/content/drive/MyDrive/Colab Notebooks/GitHub')
import numpy as np
import networkx
import csv
import pandas as pd
from tqdm import tqdm
import gzip
import re
import matplotlib.pyplot as plt
import numpy as np
from sklearn.linear_model import LogisticRegression
from metrics import metrics
from labelling import label_ADNI
from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold
import itertools
from sklearn.metrics import log_loss
import random
from sklearn.metrics import mean_squared_error
import pickle

# https://realpython.com/logistic-regression-python/

# Percorso del file GZIP
file_path = '/content/drive/MyDrive/PROJECT/chr_19_no_NaN.csv.gz'

dataset = pd.read_csv(file_path, sep='\t', dtype=str)
dataset.set_index('Unnamed: 0', inplace=True)
dataset = dataset.astype(float)
dataset

# Percorso del file GZIP
file_path = '/content/drive/MyDrive/PROJECT/lookup_snpid_gene.csv.gz'

gene_snp = pd.read_csv(file_path, sep='\t', dtype=str)
gene_snp[gene_snp['gene_name'] == 'None'] = np.nan
gene_snp = gene_snp.set_index('snpid')
gene_snp = gene_snp.drop('Unnamed: 0', axis = 1)
gene_snp = gene_snp.dropna()
usefull_snps = dataset.columns.tolist()[:-3]
gene_snp = gene_snp.loc[usefull_snps]
gene_snp

lista = gene_snp[gene_snp['gene_name'] == 'APOE'].index.tolist()#create vector with index of APOE gene and age

# Get the index of rows where the 'gene_name' column is equal to 'APOE'
lista = gene_snp[gene_snp['gene_name'] == 'APOE'].index.tolist()

# Find the indices of columns in the dataset that correspond to the 'APOE' gene
index = np.where(np.isin(dataset.columns, lista))[0]

# Remove the 'y' column (current phenotype) from the dataset
dataset = dataset.drop(['y'], axis=1)

# Create a new DataFrame with columns named after the values in 'lista'
df = pd.DataFrame(columns=lista)

# Concatenate the new DataFrame with the dataset, adding the interaction columns
dataset_2 = pd.concat([dataset, df], axis=1)

# Display the resulting dataset with the added interaction columns
dataset_2

# build the coefficients of log reg to have a 10% prob to have AD with all the snps = 1 and age = 0 and 90 % with all at1 + age = 1
weights = np.zeros([1,len(dataset_2.columns)])
weights[0, -len(index):] = 0.3
#weights[0, index[0]-1] = 1.5
model = LogisticRegression(max_iter=1000)
model.coef_ = weights
model.intercept_ = np.array([-2])
model.classes_ = np.array([0, 1])
# Store the coefficients in the dictionary using the column name as the key
coefficients = model.coef_
print(coefficients)

age = np.arange(0, 1.01, 0.01)
list_prob = []
vls = [0, 0.5, 1]
for j in vls:
  probability = []
  for i in age:
    #create a test element
    x = np.zeros([1,len(dataset_2.columns)])
    # set the age value
    x[:,len(dataset.columns)-1] = i
    #set the important snps value
    x[:,-len(index):] = j
    x = x*i
    probability.append(model.predict_proba(x)[:, 1])
    #print(x)
  list_prob.append(probability)

# Creazione del plot
plt.plot(age, np.squeeze(list_prob[0]), label='SNPs =  0')
plt.plot(age, np.squeeze(list_prob[1]), label='SNPs =  0.5')
plt.plot(age, np.squeeze(list_prob[2]), label='SNPs = 1')


# Aggiunta di etichette per gli assi x e y
plt.xlabel('Age')
plt.ylabel('Probability')

# Aggiunta di una legenda
plt.legend()
plt.title('Probability of being AD-positive in function of age')

# Mostrare il plot
plt.show()

#compute the probability to have a 0.5/0/1 in each snps based on the real data
# Get the shape of the dataset to determine the number of rows and columns
rows, cols = dataset.values.shape

# Initialize empty lists to store probabilities
prob_0 = []     # Probability of value 0
prob_0_5 = []   # Probability of value 0.5
prob_1 = []     # Probability of value 1

# Iterate over the columns of the dataset
for i in range(cols - 2):
    if i in index:
        # If the column index is in the 'index' list (indicating APOE),
        # assign fixed probabilities for each value
        prob_0.append(0.1)
        prob_0_5.append(0.1)
        prob_1.append(0.8)
    else:
        # If the column index is not in the 'index' list,
        # calculate the probabilities based on the values in the column
        snp = dataset.values.astype(float)[:, i]
        prob_0.append(np.count_nonzero(snp == 0) / rows)     # Probability of value 0 in the column
        prob_0_5.append(np.count_nonzero(snp == 0.5) / rows) # Probability of value 0.5 in the column
        prob_1.append(np.count_nonzero(snp == 1) / rows)     # Probability of value 1 in the column

#set the important snps to fixed probability to increase the probability to have positive subjects

class_1 = pd.DataFrame(columns=[*dataset.columns, 'y'])
class_0 = pd.DataFrame(columns=[*dataset.columns, 'y'])
N_pos = 0
N_neg = 0
ne1 = 0
ne0 = 0
ng = 0
n = 0
n_2 = 0
flag = []
while N_pos != 500 or N_neg != 500:
    new_element = np.array([])


    for i in range(cols-2):
        # Assign a value to each SNP based on probabilities
        value = np.random.choice([0, 0.5, 1], p=[prob_0[i], prob_0_5[i], prob_1[i]])
        new_element = np.append(new_element, value)

    # Simulate gender as a binary variable (1 = male, 0 = female)
    gender = np.random.choice([0, 1], p=[0.5, 0.5])
    new_element = np.append(new_element, gender)

    # Simulate age as a random number between 0 and 1
    age = random.uniform(0, 1)
    new_element = np.append(new_element, age)

    # Now add the values for the interaction
    new_element = np.reshape(new_element, (1, len(new_element)))


    for interaction in lista:
        snp1 = interaction
        index1 = np.where(np.isin(dataset.columns, snp1))[0][0]
        interaction_values = new_element[:, index1] * age
        new_element = np.hstack((new_element, interaction_values.reshape(-1, 1)))

    # Build the phenotype from the model
    prob = model.predict_proba(new_element)
    #print(prob)
    y = np.random.binomial(n=1, p=prob[0][1])
    flag.append(prob[0][1])
    #print(y)

    new_element = new_element[:,:-len(lista)]
    new_element = np.hstack((new_element, np.array(y).reshape(1, 1)))
    df = pd.DataFrame(new_element, columns=[*dataset.columns, 'y'])
    ng = ng+1

    if y == 1 and N_pos < 500:
      class_1 = pd.concat([class_1, df], axis=0).reset_index(drop=True)
      N_pos = N_pos+1
      n = n+1
      if prob[0][1] < 0.5:
        ne0 = ne0 + 1

    elif y == 0 and N_neg < 500:
      class_0 = pd.concat([class_0, df], axis=0).reset_index(drop=True)
      N_neg = N_neg+1
      n_2 = n_2+1
      if prob[0][1] > 0.5:
        ne1 = ne1 + 1


print('ne1 = ' + str(ne1))
print('ne0 = ' + str(ne0))
class_1

lung_datasets = [250, 500, 750, 1000]
list_datasets = []

for i in lung_datasets:
    lung = 0
    flag = 0
    indices = class_0.index.tolist()
    dataset_united = pd.DataFrame(columns=class_0.columns)

    while lung != i:
        if flag >= len(indices):
            break

        row_class_0 = class_0.iloc[indices[flag]].to_frame().T
        row_class_1 = class_1.iloc[indices[flag]].to_frame().T

        dataset_united = pd.concat([dataset_united, row_class_0], axis=0, ignore_index=True)
        dataset_united = pd.concat([dataset_united, row_class_1], axis=0, ignore_index=True)

        lung += 2
        flag += 1

    list_datasets.append(dataset_united)

list_datasets[1]

matrix = list_datasets[3].values
new_matrix = matrix[:, np.r_[:matrix.shape[1]-2, matrix.shape[1]-1]]

# Crea una nuova figura con dimensioni personalizzate
plt.figure(figsize=(15, 15))

# Visualizza la heatmap
plt.imshow(new_matrix, cmap='hot', interpolation='nearest')
plt.colorbar()

# Aggiungi titoli e etichette
plt.title("Heatmap - SNPs and Patients")
plt.xlabel("SNPs")
plt.ylabel("Patients")

# Mostra la heatmap ingrandita
plt.show()

# Calcola la media delle colonne
mean_vector = np.mean(list_datasets[3].values[:,:-3], axis=0)

# Ottieni l'indice del valore massimo nel vettore della media
max_index = np.argmax(mean_vector)
colonne = list_datasets[3].columns.tolist()
#colonne = colonne[:-3]
print('SNP: '+ str(colonne[max_index]))
print('probability to have a 0= '+str(prob_0[max_index]))
print('probability to have a 0.5= '+str(prob_0_5[max_index]))
print('probability to have a 1= '+str(prob_1[max_index]))
print('mean value = ' + str(mean_vector[max_index]))

print('gene: '+ gene_snp.loc[colonne[max_index]]['gene_name'])

with open('/content/drive/MyDrive/PROJECT/list_datasets_madeup_pheno_Age_Sex_no_processing.pickle', 'wb') as handle:
    pickle.dump(list_datasets, handle, protocol=pickle.HIGHEST_PROTOCOL)

# checkejem que s'obri correctament:
with open('/content/drive/MyDrive/PROJECT/list_datasets_madeup_pheno_Age_Sex_no_processing.pickle', 'rb') as handle:
    dataset_2 = pickle.load(handle)
dataset_2[3].shape




# -*- coding: utf-8 -*-
"""explainer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1w_S26S6BE3rGaM10K5kBanoFmkz8Im44
"""

import os
import numpy
import matplotlib.pyplot as plt
import json
import numpy as np
from google.colab import drive
import seaborn as sns
drive.mount('/content/drive')
import os.path as osp
from math import ceil
import pickle
from sklearn.metrics import balanced_accuracy_score
from sklearn.manifold import TSNE

import torch
import torch.nn.functional as F
from torch.nn import Linear

!pip install torch_geometric
!pip install --upgrade torch_geometric
!pip install umap-learn

from torch_geometric.datasets import TUDataset
from torch_geometric.loader import DataLoader
from torch_geometric.nn import DenseGraphConv, DMoNPooling, GCNConv, GATv2Conv, TopKPooling, global_mean_pool
import torch.nn as nn
from torch_geometric.utils import to_dense_adj, to_dense_batch
import matplotlib.pyplot as plt
import os
import numpy as np
import math
import json
from torch.optim.lr_scheduler import OneCycleLR
import umap
import matplotlib.animation as animation
from IPython import display
import torch.nn.functional as F
from sklearn.model_selection import ParameterGrid
import time
from torch_geometric.explain import Explainer, GNNExplainer
import random
os.chdir('/content/drive/MyDrive/Colab Notebooks/GitHub')
from metrics import metrics
from gnn_definitions import train, validation, test, GCNNet
os.chdir('/content/drive/MyDrive/Colab Notebooks/GitHub/models/GNN_grid_0.5')

class GCNNet(torch.nn.Module):
    def __init__(self, num_features, hidden_channels, num_classes, out_channels, num_layer):
        super(GCNNet, self).__init__()

        # Define a list to store the GNN layers
        self.gnn_layers = torch.nn.ModuleList()

        # Add the first GCN layer
        self.gnn_layers.append(GCNConv(num_features, hidden_channels))

        # Add additional GCN layers (if num_layer > 1)
        for _ in range(num_layer - 1):
            self.gnn_layers.append(GCNConv(hidden_channels, hidden_channels))

        # Define the first graph pooling layer
        self.pool1 = TopKPooling(hidden_channels, ratio=0.8)

        # Define two fully connected linear layers for classification
        self.lin1 = torch.nn.Linear(hidden_channels + 2, hidden_channels + 2)
        self.lin2 = torch.nn.Linear(hidden_channels + 2, out_channels)

    def forward(self, x, edge_index, batch, AGE, PTGENDER):
        # Forward pass through the GNN layers
        for conv in self.gnn_layers:
            x = F.relu(conv(x, edge_index))

        # Apply the first graph pooling layer
        x, edge_index, _, batch, _, _ = self.pool1(x, edge_index, batch = batch)

        # Compute the global mean pooling of the node embeddings, based on the batch index
        x = global_mean_pool(x, batch)

        # Concatenate AGE and PTGENDER with node embeddings
        x = torch.cat([x, AGE.unsqueeze(1), PTGENDER.unsqueeze(1)], axis=1)
        x_toprint_1 = x.clone()

        # Apply two fully connected linear layers for classification, with ReLU activation in between
        x = F.relu(self.lin1(x))
        x_toprint_2 = x.clone()

        x = self.lin2(x).squeeze(1).float()

        # Apply a sigmoid activation function to the output logits and return
        return torch.sigmoid(x)

with open('/content/drive/MyDrive/PROJECT/training_0.5_GNN_PET.pickle', 'rb') as handle:
    training_list = pickle.load(handle)

with open('/content/drive/MyDrive/PROJECT/validation_0.5_GNN_PET.pickle', 'rb') as handle:
    validation_list = pickle.load(handle)

def explain_single_model(model, model_path, data_elements):
    model.load_state_dict(torch.load(model_path))
    model.eval()

    explanations = []

    for data in data_elements:
        node_attributes = data.x
        edge_index = data.edge_index
        age = data.AGE
        ptgender = data.PTGENDER
        threshold_type = 'hard'
        value = float
        target = data.y

        # Aggiungi una dimensione per il batch per i dati ausiliari
        age = age.unsqueeze(0)       # shape: [1, num_features_age]
        ptgender = ptgender.unsqueeze(0) # shape: [1, num_features_ptgender]
        target = target.unsqueeze(0)

        # Esecuzione dell'explainer e ottenimento della spiegazione
        explanation = explainer(node_attributes, edge_index, batch=data.batch
                        , AGE=age, PTGENDER=ptgender)

        explanations.append(explanation)

    return explanations

all_explanations = []
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
winner_params_models = json.load(open('./winner_params.json','r'))
x_subgraph = []
node_mask = []
indices = []

# Definizione delle posizioni dei modelli addestrati
model_path = './PET_iteration_'+ str (7)+"/modello_"+"trial_" + str(7) + ".pt"

# Definizione delle posizioni dei dati di validazione (148 grafi)
model = GCNNet(num_features=winner_params_models['num_features'],
         hidden_channels=winner_params_models['hidden_channels'],
         num_classes=winner_params_models['num_classes'],
         out_channels=winner_params_models['out_channels'],
         num_layer=winner_params_models['num_layer']).to(device)
# Definizione dell'oggetto Explainer con GNNExplainer
explainer = Explainer(model, GNNExplainer(), explanation_type='model',
                        node_mask_type='object', edge_mask_type = "object", model_config={'return_type': 'probs',
                                                                'mode': 'binary_classification',
                                                                'task_level': 'graph'})



# Esecuzione dell'explainer per i 10 modelli e i 148 grafici nella fase di validazione
model_explanations = []

explanations = explain_single_model(model, model_path, validation_list[6])
all_explanations.append(explanations)
# Ora puoi fare i grafici delle spiegazioni utilizzando le informazioni ottenute
# con le variabili 'all_explanations' e 'validation_data_paths'.
n = 0
x_subgraph_flag = []
node_mask_flag = []
indices_flag = []

for j in range(len(explanations)):
  subgraph = explanations[j].get_explanation_subgraph()
  print(f"Spiegazione per il grafo {j+1} del modello {7}:")
  print(subgraph)
  n = n + explanations[j].target
  #explanations[j].visualize_graph(backend = 'networkx')
  x_subgraph_flag.append(subgraph.x)
  node_mask_flag.append(explanations[j].node_mask)
  indices_flag.append(torch.nonzero(explanations[j].node_mask.sum(dim=1)).squeeze().tolist())
  #print(indices_flag)

node_mask.append(node_mask_flag)
x_subgraph.append(x_subgraph_flag)
indices.append(indices_flag)

node_dict = json.load(open('/content/drive/MyDrive/PROJECT/node_dict0.5.json','r'))
gene_dict = {numero: keyword for keyword, numero in node_dict.items()}

numeri_comuni_lista = []
for i in indices:
  insiemi = [set(sottolista) for sottolista in i]
  numeri_comuni = set.intersection(*insiemi)
  numeri_comuni_lista_flag = list(numeri_comuni)
  numeri_comuni_lista.append(numeri_comuni_lista_flag)
print(len(numeri_comuni_lista))

common_genes = []
for i in numeri_comuni_lista:
  common_genes_flag = []
  for j in i:
    common_genes_flag.append(gene_dict[j])
  common_genes.append(common_genes_flag)
for i in common_genes:
  print(i)

insiemi = [set(sottolista) for sottolista in numeri_comuni_lista]
numeri_comuni = set.intersection(*insiemi)
numeri_comuni_all = list(numeri_comuni)
print(numeri_comuni_all)

common_genes_all = []
for i in numeri_comuni_all:
  common_genes_all.append(gene_dict[i])
print(common_genes_all)

import networkx as nx
import matplotlib.pyplot as plt

# Extract the subgraph of interest (in your case, explanations[0])
example_subgraph = all_explanations[0][2].get_explanation_subgraph()
nodes = example_subgraph.x
edges = example_subgraph.edge_index
node_mask_ex = all_explanations[0][2].node_mask

# Create a NetworkX Graph object
G = nx.Graph()
n = 0
new_gene_dict = {}
for i in range(len(node_mask_ex)):
    if node_mask_ex[i].numpy() != 0:
        node_name = gene_dict[i]
        G.add_node(node_name, features=nodes[n].numpy())  # Use node_name as the label
        new_gene_dict[n] = node_name
        n = n + 1

# Add edges to the graph
for edge_idx in range(edges.shape[1]):
    src, dst = edges[0][edge_idx].item(), edges[1][edge_idx].item()
    src_name, dst_name = new_gene_dict[src], new_gene_dict[dst]  # Use gene names as labels
    G.add_edge(src_name, dst_name)

# Visualize the graph with gene labels using a circular layout
pos = nx.kamada_kawai_layout(G)  # Change the layout to 'circular_layout'
nx.draw(G, pos, with_labels=True, node_color='skyblue', node_size=100, font_size=8, font_color='black')
plt.title('Subgraph example')
# Save the plot
plt.savefig("./subgraph_example.png")
plt.show()

graph = nx.Graph()
graph.add_nodes_from(range(validation_list[0][0].num_nodes))
graph.add_edges_from(validation_list[0][0].edge_index.t().tolist())

# Iterate over the nodes and assign the corresponding node names
for i, node in enumerate(graph.nodes()):
    node_name = gene_dict[i]
    graph.nodes[node]['name'] = node_name

pos = nx.kamada_kawai_layout(graph)  # Change the layout to 'kamada_kawai_layout'
nx.draw(graph, pos, labels=nx.get_node_attributes(graph, 'name'), node_color='skyblue', node_size=100, font_size=8, font_color='black')
plt.title('Graph with gene labels')
plt.show()

# Rimuovi i nodi non presenti in common_genes_all
nodes_to_remove = [node_name for node_name in G.nodes() if node_name not in common_genes_all]
G.remove_nodes_from(nodes_to_remove)

# Visualize the modified graph with gene labels
pos = nx.spring_layout(G)  # You can choose a layout of your preference
nx.draw(G, pos, with_labels=True, node_color='skyblue', node_size=100, font_size=8, font_color='black')
plt.title('Subgraph with common genes')
plt.show()